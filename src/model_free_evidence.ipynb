{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from itertools import combinations, chain\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import spearmanr\n",
    "from pygam import LogisticGAM, s, f\n",
    "\n",
    "# Visualization\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "# Serialization\n",
    "import joblib\n",
    "\n",
    "# Custom\n",
    "from pre_processing import *\n",
    "from training import *\n",
    "from plotting import *\n",
    "from testing import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, fisher_exact, chi2_contingency\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb874557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_response_drink_occasions = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../../results\"\n",
    "\n",
    "data_study1 = pd.read_csv('../data/intervention_time/osf_study1.csv')\n",
    "data_study2 = pd.read_csv('../data/intervention_time/osf_study2.csv')\n",
    "\n",
    "# Study 1 baseline data (train/val input)\n",
    "b1_alcohol_self = pd.read_csv('../data/baseline/alcoholself_bucket280225.csv', index_col=0)\n",
    "b2_group_subjective = pd.read_csv('../data/baseline/subjective_grouperceptions_280225.csv', index_col=0)\n",
    "b3_group_sociometric = pd.read_csv('../data/baseline/data_social.csv')\n",
    "b4_brain = pd.read_csv('../data/baseline/brain_bucket_280225.csv', index_col=0)\n",
    "b5_demographic = pd.read_csv('../data/baseline/demographic_bucket280225.csv', index_col=0)\n",
    "b6_psychometric = pd.read_csv('../data/baseline/psychometrics_bucket280225.csv', index_col=0)\n",
    "\n",
    "# # Added analysis - To evaluate performance of objective drinking metrics\n",
    "# b7_objective_group_drinking = pd.read_csv('../data/added_analysis/social_group_drinking.csv', index_col=0)\n",
    "\n",
    "# Study 2 peer perception data (test input)\n",
    "b2_group_subjective_study2 = pd.read_csv('/Users/fmagdalena/Documents/GitHub/shine-network-analysis/SHINE/final_buckets/subjective_grouperceptions_test.csv')\n",
    "baseline_demo_study2 = pd.read_csv('/Users/fmagdalena/Documents/GitHub/SHINE-responsiveness-analysis/data/baseline/demo_study2_full.csv')\n",
    "\n",
    "# Study 1 & 2 drinking/responsiveness data (output -> prediction target)\n",
    "if def_response_drink_occasions == -1:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == -0.5:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_-0_5.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == -2:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_-2.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == 'who':\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_who_rdl.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == -0.9:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_-0.9.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == -1.5:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_-1.5.csv', index_col=0).reset_index()\n",
    "elif def_response_drink_occasions == -0.1:\n",
    "    responsive_study1 = pd.read_csv('../data/intervention_time/responsiveness_study1_-0.1.csv', index_col=0).reset_index()\n",
    "\n",
    "responsive_study2 = pd.read_csv('../data/intervention_time/responsiveness_study2.csv', index_col=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates within each DataFrame\n",
    "duplicates_study1 = responsive_study1['id'].duplicated().any()\n",
    "duplicates_study2 = responsive_study2['id'].duplicated().any()\n",
    "\n",
    "print(f\"Study 1 has duplicates: {duplicates_study1}\")\n",
    "print(f\"Study 2 has duplicates: {duplicates_study2}\")\n",
    "\n",
    "# Check for overlapping IDs between the two studies\n",
    "ids_study1 = set(responsive_study1['id'])\n",
    "ids_study2 = set(responsive_study2['id'])\n",
    "overlap = ids_study1.intersection(ids_study2)\n",
    "\n",
    "print(f\"Number of overlapping IDs: {len(overlap)}\") # Should be zero\n",
    "if overlap:\n",
    "    print(f\"Overlapping IDs: {overlap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65685d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE_VARS = [\n",
    "    'group', 'condition', 'active',\n",
    "    'control', 'difference_drinks_occasions']\n",
    "\n",
    "# responsive_study1 = responsive_study1[responsive_study1.condition == 'mindful']\n",
    "# responsive_study2 = responsive_study2[responsive_study2.condition == 'mindful']\n",
    "\n",
    "responsive_study1.drop(columns=EXCLUDE_VARS, inplace=True, errors='ignore')\n",
    "responsive_study2.drop(columns=EXCLUDE_VARS, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training datasets -> Study 1\n",
    "b1_alcohol_self_response = pd.merge(b1_alcohol_self, responsive_study1, on='id', how='inner')\n",
    "b2_group_subjective_response = pd.merge(b2_group_subjective, responsive_study1, on='id', how='inner')\n",
    "b2_group_subjective_response_old = pd.merge(responsive_study1, responsive_study1, on='id', how='inner')\n",
    "b3_group_sociometric_response = pd.merge(b3_group_sociometric, responsive_study1, on='id', how='inner')\n",
    "b4_brain_response = pd.merge(b4_brain, responsive_study1, on='id', how='inner')\n",
    "b5_demographic_response = pd.merge(b5_demographic, responsive_study1, on='id', how='inner')\n",
    "b6_psychometric_response = pd.merge(b6_psychometric, responsive_study1, on='id', how='inner')\n",
    "\n",
    "# b7_objective_group_drinking_response = pd.merge(b7_objective_group_drinking, responsive_study1, on='id', how='inner')\n",
    "\n",
    "print(f'Total IDs Study 1: {len(b1_alcohol_self_response)}')\n",
    "print(f'Responsive IDs Study 1: {b1_alcohol_self_response[b1_alcohol_self_response[\"responsive\"] == 1][\"id\"].nunique()}')\n",
    "print('----------')\n",
    "# Testing dataset -> Study 2\n",
    "b2_group_subjective_test = pd.merge(b2_group_subjective_study2, responsive_study2, on='id', how='inner')\n",
    "print(f'Total IDs Study 2: {len(b2_group_subjective_test)}')\n",
    "print(f'Responsive IDs Study 2: {b2_group_subjective_test[b2_group_subjective_test[\"responsive\"] == 1][\"id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7095d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'alc_self': b1_alcohol_self_response,\n",
    "    'group_sub': b2_group_subjective_response,\n",
    "    'group_socio': b3_group_sociometric_response,\n",
    "    'brain': b4_brain_response,\n",
    "    'demo': b5_demographic_response,\n",
    "    'psych': b6_psychometric_response\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b800b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features within-bucket\n",
    "\n",
    "dataframes['brain'].drop(columns=['reward', 'ROI_alc_react_v_rest_neurosynth_cogcontrol', 'ROI_alc_react_v_rest_neurosynth_craving', \\\n",
    "                                  'ROI_alc_react_v_rest_neurosynth_emoreg'], inplace=True)\n",
    "\n",
    "# dataframes['group_socio'].drop(columns=['leaders_deg_in', 'goToBad_deg_in'], inplace=True)\n",
    "\n",
    "dataframes['psych'].drop(columns=['ACS_focus', 'DERS_strategies', 'BIS_attention_total'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb04106",
   "metadata": {},
   "source": [
    "## Non-parametric significance tests to check for significant variables between responders and non-repsonders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if 'responsive' not in df.columns:\n",
    "        continue\n",
    "\n",
    "    df_results = []  # store results for this dataframe\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in ['id', 'responsive']:\n",
    "            continue\n",
    "\n",
    "        x = df[col].dropna()\n",
    "        y = df.loc[x.index, 'responsive']\n",
    "\n",
    "        if len(x.unique()) <= 1:\n",
    "            continue\n",
    "\n",
    "        if np.issubdtype(x.dtype, np.number) and len(x.unique()) > 2:\n",
    "            try:\n",
    "                stat, p = mannwhitneyu(\n",
    "                    x[y == 0], x[y == 1], alternative='two-sided'\n",
    "                )\n",
    "                test_type = 'Mann-Whitney U'\n",
    "            except Exception:\n",
    "                stat, p, test_type = np.nan, np.nan, 'error'\n",
    "\n",
    "        else:\n",
    "            contingency = pd.crosstab(y, x)\n",
    "            if contingency.shape == (2, 2):\n",
    "                stat, p = fisher_exact(contingency)\n",
    "                test_type = 'Fisher exact'\n",
    "            else:\n",
    "                stat, p, _, _ = chi2_contingency(contingency)\n",
    "                test_type = 'Chi-square'\n",
    "\n",
    "        df_results.append({\n",
    "            'dataframe': name,\n",
    "            'variable': col,\n",
    "            'test': test_type,\n",
    "            'statistic': stat,\n",
    "            'p_value': p\n",
    "        })\n",
    "\n",
    "    # FDR correction within this dataframe\n",
    "    df_results = pd.DataFrame(df_results)\n",
    "    if not df_results.empty:\n",
    "        _, p_adj, _, _ = multipletests(df_results['p_value'], method='fdr_bh')\n",
    "        df_results['p_value_adj'] = p_adj\n",
    "        results.append(df_results)\n",
    "\n",
    "results_df = pd.concat(results, ignore_index=True)\n",
    "results_df = results_df.sort_values(['dataframe', 'p_value_adj'])\n",
    "results_df.to_csv('./nonparametric_tests_results_fdr.csv', index=False)\n",
    "results_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a610da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if 'responsive' not in df.columns:\n",
    "        continue\n",
    "\n",
    "    df_results = []  # store results for this dataframe\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in ['id', 'responsive']:\n",
    "            continue\n",
    "\n",
    "        x = df[col].dropna()\n",
    "        y = df.loc[x.index, 'responsive']\n",
    "\n",
    "        if len(x.unique()) <= 1:\n",
    "            continue\n",
    "\n",
    "        # default: no stats\n",
    "        resp0_stats = \"\"\n",
    "        resp1_stats = \"\"\n",
    "\n",
    "        # compute group-wise mean (sd) for numeric features\n",
    "        if np.issubdtype(x.dtype, np.number):\n",
    "            x0 = x[y == 0]\n",
    "            x1 = x[y == 1]\n",
    "\n",
    "            if len(x0) > 0:\n",
    "                m0 = x0.mean()\n",
    "                s0 = x0.std(ddof=1)\n",
    "                resp0_stats = f\"{m0:.2f} ({s0:.2f})\"\n",
    "            if len(x1) > 0:\n",
    "                m1 = x1.mean()\n",
    "                s1 = x1.std(ddof=1)\n",
    "                resp1_stats = f\"{m1:.2f} ({s1:.2f})\"\n",
    "\n",
    "        # choose test\n",
    "        if np.issubdtype(x.dtype, np.number) and len(x.unique()) > 2:\n",
    "            try:\n",
    "                stat, p = mannwhitneyu(\n",
    "                    x[y == 0], x[y == 1], alternative='two-sided'\n",
    "                )\n",
    "                test_type = 'Mann-Whitney U'\n",
    "            except Exception:\n",
    "                stat, p, test_type = np.nan, np.nan, 'error'\n",
    "\n",
    "        else:\n",
    "            contingency = pd.crosstab(y, x)\n",
    "            if contingency.shape == (2, 2):\n",
    "                stat, p = fisher_exact(contingency)\n",
    "                test_type = 'Fisher exact'\n",
    "            else:\n",
    "                stat, p, _, _ = chi2_contingency(contingency)\n",
    "                test_type = 'Chi-square'\n",
    "\n",
    "        df_results.append({\n",
    "            'dataframe': name,\n",
    "            'variable': col,\n",
    "            'test': test_type,\n",
    "            'statistic': stat,\n",
    "            'p_value': p,\n",
    "            'non_responders_mean_sd': resp0_stats,\n",
    "            'responders_mean_sd': resp1_stats\n",
    "        })\n",
    "\n",
    "    # FDR correction within this dataframe\n",
    "    df_results = pd.DataFrame(df_results)\n",
    "    if not df_results.empty:\n",
    "        _, p_adj, _, _ = multipletests(df_results['p_value'], method='fdr_bh')\n",
    "        df_results['p_value_adj'] = p_adj\n",
    "        results.append(df_results)\n",
    "\n",
    "results_df = pd.concat(results, ignore_index=True)\n",
    "results_df = results_df.sort_values(['dataframe', 'p_value_adj'])\n",
    "results_df.to_csv('./nonparametric_tests_results_fdr.csv', index=False)\n",
    "results_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = b2_group_subjective_response.copy()\n",
    "df = df.drop(columns=['id']).dropna()\n",
    "\n",
    "X = df.drop(columns=['responsive'])\n",
    "y = df['responsive']\n",
    "\n",
    "# add intercept\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# fit logistic regression\n",
    "model = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "# print coefficients and p-values\n",
    "print(model.summary())\n",
    "\n",
    "# get simple predictive performance (AUC)\n",
    "y_pred = model.predict(X)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "print(f\"AUC = {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd8c371",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d5011",
   "metadata": {},
   "source": [
    "A logistic regression model including all subjective peer perception variables significantly predicted responsiveness (LLR p < .001, Pseudo-R² = .35).\n",
    "\n",
    "**Table X. Logistic regression predicting responsiveness from subjective peer perception variables (group_sub).**\n",
    "\n",
    "| Predictor            | β (SE)    | z       | p       | 95% CI (Lower, Upper) |\n",
    "|----------------------|-----------|---------:|---------:|-----------------------:|\n",
    "| Intercept            | -4.56 (2.53) | -1.80 | 0.072 | [-9.52, 0.41] |\n",
    "| avg_alcmost_freq     | 0.02 (0.01)  | 1.20  | 0.231 | [-0.01, 0.04] |\n",
    "| avg_alcmost          | **-0.92 (0.33)** | **-2.81** | **0.005** | **[-1.56, -0.28]** |\n",
    "| alc_norm_5_r         | 0.70 (0.36)  | 1.92  | 0.055 | [-0.01, 1.41] |\n",
    "| groupAtt_alc         | 0.43 (0.63)  | 0.68  | 0.500 | [-0.81, 1.66] |\n",
    "| groupAtt_binge       | 0.61 (0.43)  | 1.41  | 0.158 | [-0.24, 1.45] |\n",
    "\n",
    "Model fit: χ²(5) = 26.07, *p* < .001, Pseudo-*R*² = .35, AUC = 0.89.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vars_to_plot = [col for col in df.columns if col not in ['responsive', 'id']]\n",
    "\n",
    "n_vars = len(vars_to_plot)\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=int(np.ceil(n_vars / 3)), ncols=3, figsize=(15, 5 * np.ceil(n_vars / 3))\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(vars_to_plot):\n",
    "    sns.boxplot(\n",
    "        x='responsive', y=col, data=df,\n",
    "        palette=['gray', 'green'], ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('Responsive (0=No, 1=Yes)')\n",
    "    axes[i].set_ylabel('Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac44065",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
